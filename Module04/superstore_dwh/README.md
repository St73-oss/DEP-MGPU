# Практическая работа 2.1: Создание аналитического хранилища данных (DWH) для "Superstore"

## Установка dbt и создание виртуального окружения в Ubuntu 20

### 1. Создание виртуального окружения

```bash
# Создайте виртуальное окружение
python3 -m venv dbt-env

# Активируйте окружение
source dbt-env/bin/activate

# Обновите pip
pip install --upgrade pip
```

### 2. Установка dbt

```bash
# Установите dbt для PostgreSQL
pip install dbt-postgres

# Проверьте установку
dbt --version
```

### 3. Настройка проекта

```bash
# Перейдите в каталог проекта
cd ~/Downloads/pde_magistr/superstore_dwh

# Проверьте подключение к базе данных
dbt debug
```

## Архитектура проекта

### Многоуровневая архитектура dbt

```
┌─────────────────────────────────────────────────────────────────┐
│                        PostgreSQL Database                      │
├─────────────────────────────────────────────────────────────────┤
│  stg schema          │  dw_test schema                         │
│  (staging)           │  (marts)                                │
│                      │                                         │
│  ┌─────────────────┐ │  ┌─────────────────┐ ┌─────────────────┐ │
│  │ stg_orders      │ │  │ customer_dim    │ │ product_dim     │ │
│  │ (очищенные      │ │  │ (измерение      │ │ (измерение      │ │
│  │  данные)        │ │  │  клиентов)      │ │  продуктов)     │ │
│  └─────────────────┘ │  └─────────────────┘ └─────────────────┘ │
│                      │  ┌─────────────────┐ ┌─────────────────┐ │
│                      │  │ geo_dim         │ │ shipping_dim    │ │
│                      │  │ (измерение      │ │ (измерение      │ │
│                      │  │  географии)     │ │  доставки)      │ │
│                      │  └─────────────────┘ └─────────────────┘ │
│                      │  ┌─────────────────┐ ┌─────────────────┐ │
│                      │  │ calendar_dim    │ │ sales_fact      │ │
│                      │  │ (измерение      │ │ (таблица        │ │
│                      │  │  календаря)     │ │  фактов)        │ │
│                      │  └─────────────────┘ └─────────────────┘ │
└─────────────────────────────────────────────────────────────────┘
                                │
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│                        dbt Project                             │
├─────────────────────────────────────────────────────────────────┤
│  models/staging/     │  models/marts/                          │
│                      │                                         │
│  ┌─────────────────┐ │  ┌─────────────────┐ ┌─────────────────┐ │
│  │ stg_orders.sql  │ │  │ customer_dim.sql│ │ product_dim.sql │ │
│  │                 │ │  │                 │ │                 │ │
│  └─────────────────┘ │  └─────────────────┘ └─────────────────┘ │
│                      │  ┌─────────────────┐ ┌─────────────────┐ │
│                      │  │ geo_dim.sql     │ │ shipping_dim.sql│ │
│                      │  │                 │ │                 │ │
│                      │  └─────────────────┘ └─────────────────┘ │
│                      │  ┌─────────────────┐ ┌─────────────────┐ │
│                      │  │ calendar_dim.sql│ │ sales_fact.sql  │ │
│                      │  │                 │ │                 │ │
│                      │  └─────────────────┘ └─────────────────┘ │
└─────────────────────────────────────────────────────────────────┘
                                │
                                ▼
┌─────────────────────────────────────────────────────────────────┐
│                    Data Flow (staging → marts)                 │
├─────────────────────────────────────────────────────────────────┤
│  stg_orders          │  customer_dim        │  sales_fact      │
│  (очищенные данные)  │  (справочник         │  (таблица фактов │
│                      │   клиентов)          │   с метриками)   │
│                      │                      │                  │
│  ┌─────────────────┐ │  ┌─────────────────┐ │  ┌─────────────┐ │
│  │ Приведение      │ │  │ Суррогатные     │ │  │ Объединение │ │
│  │ типов данных    │ │  │ ключи           │ │  │ всех        │ │
│  │ Очистка         │ │  │ Атрибуты        │ │  │ измерений   │ │
│  │ Валидация       │ │  │ клиентов        │ │  │ Метрики     │ │
│  └─────────────────┘ │  └─────────────────┘ │  └─────────────┘ │
└─────────────────────────────────────────────────────────────────┘
```

### Поток данных

1. **Staging** → Очистка и подготовка сырых данных
2. **Marts** → Создание таблиц измерений и фактов
3. **Схема-звезда** → Классическая архитектура DWH

## Основные этапы работы

### Этап 1: Подготовка данных (Staging)

Каждый из нас сталкивался с проблемой: данные для отчетов берутся из разных источников, метрики считаются по-разному, а на вопрос "какая у нас выручка за прошлый месяц?" можно получить три разных ответа. Это — прямой путь к неверным решениям.

Чтобы решить эту проблему, мы внедрили современный подход к обработке данных — **ELT: Extract, Load, Transform**. В отличие от старого подхода ETL, мы не тратим время на сложную обработку данных *перед* загрузкой в базу. Мы сначала быстро *загружаем (Load)* все сырые данные в специальную область, которую мы назвали *staging*.

И уже затем, внутри нашей мощной базы данных PostgreSQL, в игру вступает главный инструмент — **dbt**. Он выполняет шаг *трансформации (Transform)*: очищает, структурирует и обогащает данные, превращая их в готовый к анализу продукт. Такой подход гораздо гибче, быстрее и лучше масштабируется.

### Этап 2: Создание аналитического хранилища (Marts)

Вся логика трансформации заключена в dbt-проекте. Это не просто набор SQL-скриптов, это структурированный инженерный проект.

Мы разделили его на два ключевых слоя:

**Staging (папка `staging`)**: Это наша "прихожая" для данных. Здесь мы берем сырую таблицу `stg.orders`, приводим типы данных, исправляем ошибки, такие как отсутствующие почтовые индексы, и создаем базовую, очищенную модель `stg_orders`. Это отправная точка для всей дальнейшей логики.

**Marts (папка `marts`)**: Это наш "выставочный зал". Здесь находятся готовые к использованию аналитические таблицы. Мы реализовали классическую *"схему-звезду"*:

- Таблицы-измерения (Dimensions), такие как `customer_dim` и `product_dim`. Это наши справочники — "кто", "что", "где".
- И *таблица фактов (sales_fact)*, которая является сердцем хранилища и объединяет все измерения, храня метрики — "сколько" и "когда".

Ключевая магия dbt здесь — это функции `source` и `ref`, которые автоматически выстраивают зависимости между моделями. Мы не управляем порядком выполнения скриптов вручную — dbt делает это за нас.

## Команды для работы с проектом

### Основные команды

```bash
# 1. Активировать окружение
source dbt-env/bin/activate

# 2. Перейти в папку проекта
cd ~/Downloads/pde_magistr/superstore_dwh

# 3. Запустить все модели
dbt run

# 4. Запустить тесты
dbt test

# 5. Генерация документации
dbt docs generate
dbt docs serve
```

### Правильный цикл разработки

1. **Изменили код модели**
2. **Выполнили `dbt run`** (или `dbt run --select имя_модели`), чтобы обновить данные в DWH
3. **Выполнили `dbt test`**, чтобы убедиться, что изменения не нарушили качество данных

## Обеспечение качества данных

Но просто построить модели недостаточно. Как мы можем им доверять? Раньше для этого приходилось писать громоздкие проверочные запросы. С dbt мы внедряем культуру качества данных прямо в процесс разработки.

Мы написали простые, декларативные *тесты* прямо в `.yml` файлах рядом с нашими моделями. Мы проверяем:

- Что суррогатные ключи в справочниках *уникальны* и *не пусты* (`unique`, `not_null`)
- И самое главное — что каждая запись в таблице фактов имеет соответствующую запись в таблице измерений. Это тест на *целостность данных* (`relationships`)

Команда `dbt test` автоматически запускает все эти проверки. Как вы видите, все 9 тестов успешно пройдены. Это означает, что наше хранилище не просто построено, оно *валидировано*. Мы можем быть уверены в качестве этих данных.

## Документация проекта

И, наконец, апогей нашей работы — автоматически сгенерированная документация. С помощью одной команды (`dbt docs generate`) мы получили интерактивный веб-сайт, описывающий весь наш проект.

Центральный элемент этой документации — *граф зависимостей*. Это не просто картинка. Это живая, интерактивная карта нашего потока данных. Мы можем в любой момент увидеть, из какой сырой таблицы рождается каждая метрика в финальной витрине.

Это решает огромную проблему "племенных знаний". Любой новый аналитик или разработчик может за 5 минут понять архитектуру нашего хранилища, не задавая лишних вопросов. Это повышает прозрачность, управляемость и снижает порог входа для работы с данными.

## Структура проекта

```
superstore_dwh/
├── models/
│   ├── staging/          # Staging модели
│   │   ├── stg_orders.sql
│   │   └── sources.yml
│   └── marts/            # Аналитические таблицы
│       ├── customer_dim.sql
│       ├── product_dim.sql
│       ├── geo_dim.sql
│       ├── shipping_dim.sql
│       ├── calendar_dim.sql
│       ├── sales_fact.sql
│       └── schema.yml
├── dbt_project.yml       # Конфигурация проекта
├── profiles.yml          # Настройки подключения к БД
└── README.md             # Документация проекта
```

## Результаты

После выполнения всех этапов вы получите:

1. **Очищенные данные** в схеме `stg`
2. **Аналитическое хранилище** в схеме `dw_test` со схемой-звездой
3. **Валидированные данные** с прошедшими тестами
4. **Автоматическую документацию** с графом зависимостей
5. **Прозрачную архитектуру** для команды аналитиков

## Дополнительные материалы

Варианты для самостоятельной работы находятся на образовательном ресурсе: [Практическая работа 2-2](http://95.131.149.21/moodle/pluginfile.php/5566/mod_assign/introattachment/0/%D0%9F%D0%A0_2-2%202025.pdf?forcedownload=1)